{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38e2599",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "graph = {\n",
    "'1':['2','5','3'],\n",
    "'2':['6', '4'],\n",
    "'5':['4'],\n",
    "'3':['4','7'],\n",
    "'6':[],\n",
    "'4':[],\n",
    "'7':[]\n",
    "}\n",
    "visited=[]\n",
    "queue=[]\n",
    "def bfs(visited,graph,node):\n",
    "visited.append(node)\n",
    "queue.append(node)\n",
    "while queue:\n",
    "m = queue.pop(0)\n",
    "print(m)\n",
    "for neighbour in graph[m]:\n",
    "if neighbour not in visited:\n",
    "visited.append(neighbour)\n",
    "queue.append(neighbour)\n",
    "print(\"Following is the Breadth-First Search\")\n",
    "bfs(visited,graph,'1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fdcec2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "graph = {\n",
    "'1':['2','5','3'],\n",
    "'2':['6', '4'],\n",
    "'5':['4'],\n",
    "'3':['4','7'],\n",
    "'6':[],\n",
    "'4':[],\n",
    "'7':[]\n",
    "}\n",
    "visited = set()\n",
    "def dfs(visited, graph, node):\n",
    "if node not in visited:\n",
    "print(node)\n",
    "visited.add(node)\n",
    "for neighbour in graph[node]:\n",
    "dfs(visited, graph, neighbour)\n",
    "print(\"Following is the Depth-First Search\")\n",
    "dfs(visited,graph,'1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d76452",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class Graph:\n",
    "    def __init__(self, adjacency_list):\n",
    "        self.adjacency_list = adjacency_list\n",
    "\n",
    "    def get_neighbors(self, v):\n",
    "        return self.adjacency_list[v]\n",
    "\n",
    "    def h(self, n):\n",
    "        H = {\n",
    "            'A': 1,\n",
    "            'B': 1,\n",
    "            'C': 1,\n",
    "            'D': 1\n",
    "        }\n",
    "        return H[n]\n",
    "\n",
    "    def a_star_algorithm(self, start_node, stop_node):\n",
    "        open_list = set([start_node])\n",
    "        closed_list = set([])\n",
    "\n",
    "        g = {}\n",
    "        g[start_node] = 0\n",
    "\n",
    "        parents = {}\n",
    "        parents[start_node] = start_node\n",
    "\n",
    "        while len(open_list) > 0:\n",
    "            n = None\n",
    "\n",
    "            for v in open_list:\n",
    "                if n is None or g[v] + self.h(v) < g[n] + self.h(n):\n",
    "                    n = v\n",
    "\n",
    "            if n is None:\n",
    "                print('Path does not exist!')\n",
    "                return None\n",
    "\n",
    "            if n == stop_node:\n",
    "                reconst_path = []\n",
    "\n",
    "                while parents[n] != n:\n",
    "                    reconst_path.append(n)\n",
    "                    n = parents[n]\n",
    "\n",
    "                reconst_path.append(start_node)\n",
    "                reconst_path.reverse()\n",
    "\n",
    "                print('Path found: {}'.format(reconst_path))\n",
    "                return reconst_path\n",
    "\n",
    "            for (m, weight) in self.get_neighbors(n):\n",
    "                if m not in open_list and m not in closed_list:\n",
    "                    open_list.add(m)\n",
    "                    parents[m] = n\n",
    "                    g[m] = g[n] + weight\n",
    "                else:\n",
    "                    if g[m] > g[n] + weight:\n",
    "                        g[m] = g[n] + weight\n",
    "                        parents[m] = n\n",
    "\n",
    "                        if m in closed_list:\n",
    "                            closed_list.remove(m)\n",
    "                            open_list.add(m)\n",
    "\n",
    "            open_list.remove(n)\n",
    "            closed_list.add(n)\n",
    "\n",
    "        print('Path does not exist!')\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "adjacency_list = {\n",
    "    'A': [('B', 1), ('C', 3), ('D', 7)],\n",
    "    'B': [('D', 5)],\n",
    "    'C': [('D', 12)]\n",
    "}\n",
    "graph1 = Graph(adjacency_list)\n",
    "graph1.a_star_algorithm('A', 'D')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4908428",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "V = {'A': 7, 'B': 9, 'C': 6, 'D': 5, 'E': 6, 'F': 4.5, 'H': 4, 'I': 2, 'J': 3, 'K': 3.5, 'G': 0}\n",
    "E = {\n",
    "    ('B', 'D'): 2, ('A', 'B'): 4, ('A', 'C'): 4, ('A', 'D'): 7, ('D', 'E'): 6,\n",
    "    ('E', 'F'): 5, ('D', 'F'): 8, ('D', 'H'): 5, ('H', 'I'): 3, ('I', 'J'): 3,\n",
    "    ('J', 'K'): 3, ('K', 'H'): 3, ('F', 'G'): 5\n",
    "}\n",
    "\n",
    "INFINITY = 10000000\n",
    "cameFrom = {}\n",
    "\n",
    "def h(node):\n",
    "    return V[node]\n",
    "\n",
    "def cost(node, succ):\n",
    "    return E[(node, succ)]\n",
    "\n",
    "def successors(node):\n",
    "    neighbours = []\n",
    "    for edge in E:\n",
    "        if node == edge[0]:\n",
    "            neighbours.append(edge[1])\n",
    "    return neighbours\n",
    "\n",
    "def reconstruct_path(cameFrom, current):\n",
    "    total_path = [current]\n",
    "    while current in cameFrom:\n",
    "        current = cameFrom[current]\n",
    "        total_path.append(current)\n",
    "    return total_path[::-1]\n",
    "\n",
    "def ida_star(root, goal):\n",
    "    global cameFrom\n",
    "\n",
    "    def search(node, g, bound):\n",
    "        nonlocal cameFrom\n",
    "        f = g + h(node)\n",
    "        if f > bound:\n",
    "            return f\n",
    "        if node == goal:\n",
    "            return \"FOUND\"\n",
    "        minn = INFINITY\n",
    "        for succ in successors(node):\n",
    "            t = search(succ, g + cost(node, succ), bound)\n",
    "            if t == \"FOUND\":\n",
    "                cameFrom[succ] = node\n",
    "                return \"FOUND\"\n",
    "            if t < minn:\n",
    "                minn = t\n",
    "                cameFrom[succ] = node\n",
    "        return minn\n",
    "\n",
    "    bound = h(root)\n",
    "    count = 1\n",
    "    while True:\n",
    "        print(\"iteration \" + str(count))\n",
    "        count += 1\n",
    "        t = search(root, 0, bound)\n",
    "        if t == \"FOUND\":\n",
    "            print(reconstruct_path(cameFrom, goal))\n",
    "            return bound\n",
    "        if t == INFINITY:\n",
    "            return \"NOT_FOUND\"\n",
    "        bound = t\n",
    "\n",
    "# Run the algorithm\n",
    "print(ida_star('A', 'G'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ab7f44",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "from pgmpy.inference import VariableElimination\n",
    "import numpy as np\n",
    "bayesNet = BayesianModel()\n",
    "bayesNet.add_node(\"M\")\n",
    "bayesNet.add_node(\"U\")\n",
    "bayesNet.add_node(\"R\")\n",
    "bayesNet.add_node(\"B\")\n",
    "bayesNet.add_node(\"S\")\n",
    "bayesNet.add_edge(\"M\",\"R\")\n",
    "bayesNet.add_edge(\"U\",\"R\")\n",
    "bayesNet.add_edge(\"B\",\"R\")\n",
    "bayesNet.add_edge(\"B\",\"S\")\n",
    "bayesNet.add_edge(\"R\",\"S\")\n",
    "cpd_A = TabularCPD('M', 2, values=[[.95],[.05]])\n",
    "cpd_U = TabularCPD('U', 2, values=[[.85],[.15]])\n",
    "cpd_H = TabularCPD('B', 2, values=[[.90],[.10]])\n",
    "cpd_S = TabularCPD('S', 2, values=[[.98,.88,.95,.6],[.02,.12,.05,.40]],\n",
    "evidence = ['R','B'], evidence_card=[2,2])\n",
    "cpd_R = TabularCPD('R', 2, values=[[.96,.86,.94,.82,.24,.15,.10,.05],[.04,.14,.06,.18,.76,.85,.9\n",
    "0,.95]],\n",
    "evidence = ['M','B','U'], evidence_card=[2,2,2])\n",
    "bayesNet.add_cpds(cpd_A,cpd_U,cpd_H,cpd_S,cpd_R)\n",
    "bayesNet.check_model()\n",
    "print(\"Model is correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e1d78a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "x=[14,16,27,42,39,50,83]\n",
    "y=[2,5,7,9,10,13,20]\n",
    "xy=0 x2=0\n",
    "xy_all=0 x2_all=0 x_all=0\n",
    "y_all=0\n",
    "for i in range(7):\n",
    "xy_all=xy_all+x[i]*y[i]\n",
    "x2_all=x2_all+x[i]*x[i]\n",
    "x_all=x_all+x[i]\n",
    "y_all=y_all+y[i]\n",
    "x_bar=x_all/7\n",
    "y_bar=y_all/7\n",
    "b=(xy_all7*x_bar*y_bar)/(x2_all7*x_bar*x_bar) a=(y_barb*x_bar)\n",
    "print(b)\n",
    "print(a)\n",
    "print(\"Y=\",b,\"(X)+\",a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045c97e1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "plt.plot(y_test,y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d56ad78",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "df = pd.read_csv(\"train_data.csv\")\n",
    "target = df[\"target\"]\n",
    "train = df.drop(\"target\")\n",
    "X_train, X_test, y_train, y_test = train_test_split( train, target, test_size=0.20)\n",
    "model = BaggingRegressor(base_estimator=xgb.XGBRegressor())\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "print(mean_squared_error(y_test, pred_final)) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "df = pd.read_csv(\"train_data.csv\")\n",
    "target = df[\"target\"]\n",
    "train = df.drop(\"target\")\n",
    "X_train, X_test, y_train, y_test = train_test_split( train, target, test_size=0.20)\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "pred_final = model.predict(X_test)\n",
    "print(mean_squared_error(y_test, pred_final))\n",
    "\n",
    "\n",
    "mport pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from vecstack import stacking\n",
    "df = pd.read_csv(\"train_data.csv\")\n",
    "target = df[\"target\"]\n",
    "train = df.drop(\"target\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "train, target, test_size=0.20)\n",
    "model_1 = LinearRegression()\n",
    "model_2 = xgb.XGBRegressor()\n",
    "model_3 = RandomForestRegressor()\n",
    "all_models = [model_1, model_2, model_3]\n",
    "s_train, s_test = stacking(all_models, X_train, X_test,\n",
    "y_train, regression=True, n_folds=4)\n",
    "final_model = model_1\n",
    "del = final_model.fit(s_train, y_train) pred_final = final_model.predict(X_test)\n",
    "print(mean_squared_error(y_test, pred_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001b3e79",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "x = data.drop(\"Outcome\", axis=1)\n",
    "y = data[\"Outcome\"]\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation=\"relu\"))\n",
    "model.add(Dense(12, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
    "metrics=[\"accuracy\"]) model.fit(x,y, epochs=5, batch_size=10)\n",
    "_, accuracy = model.evaluate(x, y)\n",
    "print(\"Model accuracy: %.2f\"% (accuracy*100))\n",
    "predictions = model.predict(x)\n",
    "print([round(x[0]) for x in predictions])\n",
    "model = Sequential() #define model\n",
    "model.add(Dense(12, input_dim=8, activation=\"relu\"))\n",
    "model.add(Dense(8, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
    "metrics=[\"accuracy\"]) #compile model\n",
    "model.fit(x,y, epochs=5, batch_size=10) #training\n",
    "_, accuracy = model.evaluate(x,y) #testing\n",
    "print(\"Model accuracy: %.2f\"% (accuracy*100))\n",
    "predictions = model.predict(x) #make predictions\n",
    "#round the prediction\n",
    "rounded = [round(x[0]) for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f4a4c6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sigmoid activation and its derivative\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Input data for XOR\n",
    "X = np.array([[0, 0],\n",
    "              [0, 1],\n",
    "              [1, 0],\n",
    "              [1, 1]])\n",
    "\n",
    "# Output labels\n",
    "y = np.array([[0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0]])\n",
    "\n",
    "# Seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Initialize weights randomly\n",
    "input_neurons = 2\n",
    "hidden_neurons = 2\n",
    "output_neurons = 1\n",
    "\n",
    "# Weights and biases\n",
    "weights_input_hidden = np.random.uniform(size=(input_neurons, hidden_neurons))\n",
    "weights_hidden_output = np.random.uniform(size=(hidden_neurons, output_neurons))\n",
    "bias_hidden = np.random.uniform(size=(1, hidden_neurons))\n",
    "bias_output = np.random.uniform(size=(1, output_neurons))\n",
    "\n",
    "# Training parameters\n",
    "epochs = 10000\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Forward Propagation\n",
    "    hidden_input = np.dot(X, weights_input_hidden) + bias_hidden\n",
    "    hidden_output = sigmoid(hidden_input)\n",
    "    final_input = np.dot(hidden_output, weights_hidden_output) + bias_output\n",
    "    final_output = sigmoid(final_input)\n",
    "\n",
    "    # Backpropagation\n",
    "    error = y - final_output\n",
    "    d_output = error * sigmoid_derivative(final_output)\n",
    "    error_hidden = d_output.dot(weights_hidden_output.T)\n",
    "    d_hidden = error_hidden * sigmoid_derivative(hidden_output)\n",
    "\n",
    "    # Updating weights and biases\n",
    "    weights_hidden_output += hidden_output.T.dot(d_output) * learning_rate\n",
    "    weights_input_hidden += X.T.dot(d_hidden) * learning_rate\n",
    "    bias_output += np.sum(d_output, axis=0, keepdims=True) * learning_rate\n",
    "    bias_hidden += np.sum(d_hidden, axis=0, keepdims=True) * learning_rate\n",
    "\n",
    "    # Optional: Print error every 1000 epochs\n",
    "    if epoch % 1000 == 0:\n",
    "        loss = np.mean(np.square(error))\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "# Final output after training\n",
    "print(\"\\nFinal Output After Training:\")\n",
    "print(final_output)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
